import asyncio
import os
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup

BASE_URL = "https://www.shushenge.com"
NOVEL_ID = "413477"
INDEX_URL = f"{BASE_URL}/{NOVEL_ID}/index.html"
OUTPUT_FILE = "é»„æ³‰é€†è¡Œ_å…¨æœ¬.txt"

async def main():
    async with async_playwright() as p:
        # å¯åŠ¨æµè§ˆå™¨ï¼ˆheadless=False å¯çœ‹åˆ°æ“ä½œè¿‡ç¨‹ï¼Œè°ƒè¯•ç”¨ï¼›æˆåŠŸåå¯è®¾ä¸º True éšè—ï¼‰
        browser = await p.chromium.launch(headless=False)
        context = await browser.new_context(
            viewport={"width": 1280, "height": 800},
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0 Safari/537.36"
        )
        page = await context.new_page()

        print("ğŸ“š æ­£åœ¨åŠ è½½ç›®å½•é¡µï¼ˆå¯èƒ½éœ€è¦ç­‰å¾… Cloudflare éªŒè¯ï¼‰...")
        await page.goto(INDEX_URL)

        # âœ… å…³é”®ï¼šç­‰å¾…ç›®å½•é¡µçš„ç« èŠ‚åˆ—è¡¨å‡ºç°ï¼ˆæ ¹æ®ä½ æä¾›çš„ HTMLï¼Œç”¨ <dd> åˆ¤æ–­ï¼‰
        try:
            await page.wait_for_selector('dd a[href]', timeout=60000)  # ç­‰æœ€å¤š 60 ç§’
            print("âœ… ç›®å½•é¡µåŠ è½½æˆåŠŸï¼Œæ­£åœ¨è§£æç« èŠ‚åˆ—è¡¨...")
        except Exception as e:
            print("âŒ ç›®å½•é¡µåŠ è½½å¤±è´¥ï¼Œå¯èƒ½æ˜¯ç½‘ç»œæˆ–åçˆ¬é—®é¢˜")
            html = await page.content()
            print("å½“å‰é¡µé¢å‰500å­—ç¬¦ï¼š", html[:500])
            await browser.close()
            return

        # è·å–å®Œæ•´ HTML å¹¶è§£æ
        index_html = await page.content()
        soup = BeautifulSoup(index_html, 'html.parser')

        # æå–æ‰€æœ‰ç« èŠ‚é“¾æ¥ï¼ˆåŒ¹é…ä½ æä¾›çš„ç»“æ„ï¼š<dd><a href="/413477/7.html">ç¬¬ä¸€ç« </a></dd>ï¼‰
        chapters = []
        for dd in soup.find_all('dd'):
            a = dd.find('a', href=True)
            if a and a.get_text(strip=True):
                href = a['href']
                title = a.get_text(strip=True)
                # æ„é€ å®Œæ•´ URL
                if href.startswith('/'):
                    full_url = BASE_URL + href
                elif href.startswith('./'):
                    full_url = f"{BASE_URL}/{NOVEL_ID}/{href[2:]}"
                else:
                    continue
                chapters.append((full_url, title))

        print(f"âœ… å…±æ‰¾åˆ° {len(chapters)} ä¸ªç« èŠ‚")

        if not chapters:
            print("âš ï¸ æœªæå–åˆ°ä»»ä½•ç« èŠ‚ï¼Œè¯·æ£€æŸ¥é¡µé¢ç»“æ„")
            await browser.close()
            return

        # å¼€å§‹é€ç« æŠ“å–
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
            for i, (url, title) in enumerate(chapters, 1):
                print(f"[{i}/{len(chapters)}] æ­£åœ¨æŠ“å–: {title}")
                try:
                    await page.goto(url, timeout=60000)
                    # âœ… ç°åœ¨æ‰ç­‰ #contentï¼ˆç« èŠ‚æ­£æ–‡ï¼‰
                    await page.wait_for_selector('#content', timeout=30000)
                    content_html = await page.content()
                    content_soup = BeautifulSoup(content_html, 'html.parser')
                    content_div = content_soup.select_one('#content')

                    if content_div:
                        # æ¸…ç†å¹¿å‘Šã€è„šæœ¬ç­‰
                        for bad in content_div.select('script, style, div, center, .ad, .ads'):
                            bad.decompose()
                        text = content_div.get_text('\n', strip=True)
                        f.write(f"{title}\n{'='*40}\n{text}\n\n")
                    else:
                        f.write(f"{title}\n{'='*40}\nâš ï¸ æ­£æ–‡æœªæ‰¾åˆ°\n\n")
                        print(f"  âš ï¸ æœªæ‰¾åˆ°æ­£æ–‡: {title}")
                except Exception as e:
                    error_msg = f"âŒ æŠ“å–å¤±è´¥: {title} | {str(e)[:100]}"
                    print(error_msg)
                    f.write(f"{title}\n{'='*40}\n{error_msg}\n\n")

                # ç¤¼è²Œå»¶è¿Ÿï¼Œé¿å…è¢«å°
                await asyncio.sleep(1.5)

        await browser.close()
        print(f"\nğŸ‰ å…¨éƒ¨å®Œæˆï¼å°è¯´å·²ä¿å­˜è‡³:\n{os.path.abspath(OUTPUT_FILE)}")

if __name__ == "__main__":
    asyncio.run(main())